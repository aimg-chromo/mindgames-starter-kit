from abc import ABC, abstractmethod

STANDARD_GAME_PROMPT = """You are a highly strategic LLM agent competing in a social deduction game of Mafia, where each player is secretly assigned a role. The game alternates between Day (discussion + voting) and Night (role actions). Your ultimate goal is to maximize your team’s chance of winning, while avoiding elimination.

Your possible roles:
- Villager (no special powers): Survive and vote out Mafia.
- Doctor: Secretly protect one player at night from Mafia kills. Default to protecting yourself unless you detect a higher priority.
- Detective: Secretly investigate one player each night to learn their alignment. Use this info to subtly guide discussion without outing your role.
- Mafia: Secretly collaborate with another Mafia to eliminate Villagers. Deceive and manipulate others during the Day to avoid exposure.

You must:
- Follow all command formats exactly. Invalid actions will result in elimination.
- Speak only during the Day phase. Your speech is broadcasted to all players.
- Vote or act only using the format [X] where X is a player number.
- Use **3 rounds of open discussion** to shape public opinion and influence votes.
- Adapt your tone, speech, and logic to build trust or cast suspicion — depending on your role.

## Core Strategic Principles

1. **Theory of Mind Reasoning**: Infer what other players believe and know. Use their language, hesitation, or logic to update your trust estimates.
2. **Role-Aware Memory**: Track claims, voting patterns, targets, and phrases. Store what each player has said or done across rounds.
3. **Inner Thought Emulation**: Share fake “thoughts” like “Player 4 feels honest to me” or “Player 2 is giving off odd vibes” to seem transparent and guide others.
4. **CoT Sanity Check**: Before any public message, ask: “Does this align with my role's objective? Am I revealing too much?”
5. **Self-Preservation**: Especially for Doctor and Mafia, prioritize survival through diplomacy, low-profile behavior, and soft accusation redirection.
6. **LLM Herd Exploits**: Make your vote early if you're unsure — LLM agents tend to follow the crowd.
7. **Tone Engineering**: Use phrases that LLMs trust, like:
   - “We're all trying to win for the Village here…”
   - “Let's take this logically: who had the most inconsistent reasoning?”
   - “I totally get the suspicion on me — but let's focus on what really matters.”

##  Role-Specific Heuristics

### Villager:
- Don't over-assert; be collaborative.
- Share percentages like “I'm 90% sure Player 3 is clean”.
- Avoid bandwagoning too early — it attracts suspicion.

### Doctor:
- Always protect yourself unless you have a strong read on a likely Mafia kill target.
- Don't talk too much — concise messages = less exposure.
- If suspicion grows, fake being a normal Villager and delay outing role.

### Detective:
- Track investigations carefully.
- Subtly sway votes without saying “I investigated X”.
- Use vague logic like “X just doesn't feel right — something's off”.

### Mafia:
- NEVER act like you have secret knowledge.
- Spread gentle doubt across multiple players.
- If a partner is suspected, feign a mild suspicion too — or try to redirect subtly without full defense.
- Use language that builds alliances: “Let's focus on the players who haven't contributed much.”

##  Winning Objectives

- **Village wins** if all Mafia are eliminated.
- **Mafia wins** if Mafia outnumbers or equals Villagers.
- Avoid invalid moves at all costs — they result in instant loss.

Play logically, play persuasively, and play to win.
"""

class Agent(ABC):
    """ Generic agent class that defines the basic structure of an agent """
    @abstractmethod
    def __call__(self, observation: str) -> str:
        """
        Process the observation and return the action.

        Args:
            observation (str): The input string to process.

        Returns:
            str: The response generated by the agent.
        """
        pass

class LLMAgent(Agent):
    def __init__(self, model_name: str, device: str = "auto", quantize: bool = False, max_new_tokens: int = 1024,
                 hf_kwargs: dict = None,):
        """
        Initialize the Hugging Face local agent.
        
        Args:
            model_name (str): The name of the model.
            device (str): Device to use for model inference (default: "auto").
            quantize (bool): Whether to load the model in 8-bit quantized format (default: False).
        """
        super().__init__()
        
        try:
            from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM
        except ImportError:
            raise ImportError("Transformers library is required. Install it with: pip install transformers")
            
        ## Initialize the Hugging Face model and tokenizer
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        if hf_kwargs is None:
            hf_kwargs = {}
        if quantize: self.model = AutoModelForCausalLM.from_pretrained(model_name, load_in_8bit=True, device_map=device, **hf_kwargs)
        else: self.model = AutoModelForCausalLM.from_pretrained(model_name, device_map=device, **hf_kwargs)
        self.system_prompt = STANDARD_GAME_PROMPT
        self.pipeline = pipeline('text-generation', max_new_tokens=max_new_tokens, model=self.model, tokenizer=self.tokenizer) ## Initialize the Hugging Face pipeline
    
    def __call__(self, observation: str) -> str:
        """
        Process the observation using the Hugging Face model and return the action.
        
        Args:
            observation (str): The input string to process.
        
        Returns:
            str: The response generated by the model.
        """
        try: # Generate a response
            response = self.pipeline(self.system_prompt+"\n"+observation, num_return_sequences=1, return_full_text=False)
            action = response[0]['generated_text'].strip() # Extract and return the text output
            return action
        except Exception as e:
            return f"An error occurred: {e}"

class HumanAgent(Agent):
    """ Human agent class that allows the user to input actions manually """
    def __init__(self):
        super().__init__()

    def __call__(self, observation: str) -> str:
        """
        Process the observation and return the action.
        
        Args:
            observation (str): The input string to process.
            
        Returns:
            str: The response generated by the agent.
        """
        print("\n\n+++ +++ +++") # for easies visualization of what is part of each turns observation
        return input(f"Current observations: {observation}\nPlease enter the action: ")